{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('text_emotion.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Analyse du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>xxxPEACHESxxx</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ShansBee</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>mcsleazy</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>nic0lepaula</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Ingenue_Em</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment         author  \\\n",
       "0  1956967341       empty     xoshayzers   \n",
       "1  1956967666     sadness      wannamama   \n",
       "2  1956967696     sadness      coolfunky   \n",
       "3  1956967789  enthusiasm    czareaquino   \n",
       "4  1956968416     neutral      xkilljoyx   \n",
       "5  1956968477       worry  xxxPEACHESxxx   \n",
       "6  1956968487     sadness       ShansBee   \n",
       "7  1956968636       worry       mcsleazy   \n",
       "8  1956969035     sadness    nic0lepaula   \n",
       "9  1956969172     sadness     Ingenue_Em   \n",
       "\n",
       "                                             content  \n",
       "0  @tiffanylue i know  i was listenin to bad habi...  \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                Funeral ceremony...gloomy friday...  \n",
       "3               wants to hang out with friends SOON!  \n",
       "4  @dannycastillo We want to trade with someone w...  \n",
       "5  Re-pinging @ghostridah14: why didn't you go to...  \n",
       "6  I should be sleep, but im not! thinking about ...  \n",
       "7               Hmmm. http://www.djhero.com/ is down  \n",
       "8            @charviray Charlene my love. I miss you  \n",
       "9         @kelcouch I'm sorry  at least it's Friday?  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "anger          110\n",
       "boredom        179\n",
       "enthusiasm     759\n",
       "empty          827\n",
       "hate          1323\n",
       "relief        1526\n",
       "fun           1776\n",
       "surprise      2187\n",
       "love          3842\n",
       "sadness       5165\n",
       "happiness     5209\n",
       "worry         8459\n",
       "neutral       8638\n",
       "Name: tweet_id, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('sentiment').count().sort_values(by = 'tweet_id')['tweet_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.groupby('sentiment').count().sort_values(by = 'tweet_id')['tweet_id'].plot(figsize=(10,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We here have an unbalanced Dataset.\n",
    "\n",
    "Emphasis will need to be put on unrepresented labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 4 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize(progress_bar = True)\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Cleaning First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(string):\n",
    "    \"\"\"\n",
    "    Remove digits from a string\n",
    "    :param string: a string\n",
    "    :return: the string without the digits\n",
    "    \"\"\"\n",
    "    result = ''.join([i for i in string if not i.isdigit()])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_word_exaggeration(comment_string):\n",
    "    \"\"\"\n",
    "    Reduces word exaggeration such as 'veeeeery' to 'veery' \n",
    "    :param comment_string: string containing the review\n",
    "    :return: cleaned review string\n",
    "    \"\"\"\n",
    "    exaggeration = re.compile(r\"(.)\\1{2,}\")\n",
    "    return exaggeration.sub(r\"\\1\\1\", comment_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_to_tokens(raw_string, spacy_nlp):\n",
    "    \"\"\"\n",
    "    cleaning pipeline to be called on each review.\n",
    "    :param comment_string: string containing the review, and spaCy nlp model.\n",
    "    :return: cleaned review string\n",
    "    \"\"\"\n",
    "    string = raw_string.lower()\n",
    "        \n",
    "    string = remove_digits(string)\n",
    "    \n",
    "    string = reduce_word_exaggeration(string)\n",
    "    \n",
    "    spacy_tokens = spacy_nlp(string)\n",
    "    \n",
    "    # Remove ponctuation, stop words, and '  ':    \n",
    "    string_tokens = [token.orth_ for token in spacy_tokens if not token.is_punct and not token.is_stop and not token.orth_ == '  ']\n",
    "    \n",
    "    clean_string = \" \".join(string_tokens)\n",
    "    \n",
    "    return clean_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['content_clean'] = df.parallel_apply(lambda x : raw_to_tokens(x['content'], nlp), axis = 1)\n",
    "df.to_csv('df_preprocessed_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('df_preprocessed_2.csv', index_col=0)\n",
    "df.dropna(subset = ['content_clean'], axis = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('day', 3185),\n",
       " ('good', 2331),\n",
       " ('like', 1936),\n",
       " ('got', 1848),\n",
       " ('today', 1644),\n",
       " ('work', 1629),\n",
       " ('love', 1627),\n",
       " ('going', 1571),\n",
       " ('nt', 1505),\n",
       " ('happy', 1480)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lists_of_words = [content.split() for content in df.content_clean.values]\n",
    "list_of_words = [word for sublist in lists_of_words for word in sublist]\n",
    "word_freq = Counter(list_of_words)\n",
    "word_freq.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common words for sentiment: empty: \n",
      " [('bored', 38), ('work', 37), ('nt', 37), ('got', 33), ('day', 33), ('m', 29), ('today', 29), ('home', 27), ('like', 27), ('twitter', 26)]\n",
      "Most common words for sentiment: sadness: \n",
      " [('sad', 384), ('day', 356), ('miss', 343), ('work', 329), ('today', 283), ('like', 278), ('nt', 277), ('got', 262), ('m', 250), ('going', 216)]\n",
      "Most common words for sentiment: enthusiasm: \n",
      " [('good', 55), ('want', 44), ('day', 42), ('today', 37), ('got', 37), ('work', 35), ('like', 34), ('new', 34), ('going', 33), ('u', 31)]\n",
      "Most common words for sentiment: neutral: \n",
      " [('day', 424), ('good', 363), ('work', 337), ('like', 337), ('going', 314), ('got', 309), ('today', 280), ('know', 273), ('nt', 266), ('time', 256)]\n",
      "Most common words for sentiment: worry: \n",
      " [('like', 454), ('got', 453), ('nt', 449), ('day', 443), ('good', 394), ('work', 393), ('going', 384), ('today', 374), ('know', 358), ('m', 340)]\n",
      "Most common words for sentiment: surprise: \n",
      " [('day', 132), ('oh', 122), ('nt', 110), ('got', 107), ('good', 101), ('like', 97), ('know', 95), ('going', 87), ('lol', 84), ('u', 80)]\n",
      "Most common words for sentiment: love: \n",
      " [('love', 862), ('day', 784), ('happy', 599), ('good', 324), ('mothers', 303), ('mother', 299), ('thanks', 196), ('like', 185), ('u', 182), ('mom', 149)]\n",
      "Most common words for sentiment: fun: \n",
      " [('lol', 188), ('fun', 143), ('good', 117), ('day', 105), ('haha', 104), ('like', 103), ('going', 85), ('u', 82), ('got', 79), ('night', 73)]\n",
      "Most common words for sentiment: hate: \n",
      " [('hate', 210), ('like', 94), ('work', 85), ('nt', 79), ('sucks', 72), ('got', 58), ('day', 54), ('want', 52), ('going', 51), ('damn', 49)]\n",
      "Most common words for sentiment: happiness: \n",
      " [('day', 646), ('good', 574), ('happy', 417), ('thanks', 297), ('great', 295), ('lol', 292), ('got', 282), ('today', 262), ('like', 235), ('haha', 224)]\n",
      "Most common words for sentiment: boredom: \n",
      " [('bored', 30), ('m', 19), ('work', 15), ('like', 12), ('tired', 11), ('today', 10), ('amp', 10), ('boring', 10), ('getting', 9), ('nt', 9)]\n",
      "Most common words for sentiment: relief: \n",
      " [('day', 155), ('good', 127), ('thanks', 93), ('got', 91), ('finally', 85), ('time', 83), ('today', 80), ('like', 75), ('home', 74), ('work', 71)]\n",
      "Most common words for sentiment: anger: \n",
      " [('good', 7), ('nt', 6), ('m', 6), ('know', 6), ('work', 6), ('like', 5), ('got', 5), ('people', 5), ('going', 5), ('day', 5)]\n"
     ]
    }
   ],
   "source": [
    "for sentiment in df.sentiment.unique():\n",
    "    df_subset_sentiment = df.loc[df.sentiment == sentiment]\n",
    "    lists_of_words = [content.split() for content in df_subset_sentiment.content_clean.values]\n",
    "    list_of_words = [word for sublist in lists_of_words for word in sublist]\n",
    "    word_freq = Counter(list_of_words)\n",
    "    word_freq.most_common(10)\n",
    "    print('Most common words for sentiment: {}: \\n {}'.format(sentiment, word_freq.most_common(10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we typically wnat to use a representation of words that such as TF-IDF.\n",
    "\n",
    "We can apply it on the original content, but it is also recommended to apply it on the cleaned data.\n",
    "\n",
    "For sentiment analysis, it ill also be interesting to try and only use adjectives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adds some complexity (usefull ?)\n",
    "def get_adjectives(content):\n",
    "    content_adj = [token.orth_ for token in nlp(content) if token.pos_ == \"ADJ\"]\n",
    "    return \" \".join(content_adj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No time to run it here:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['adjectives'] = df['content_clean'].parallel_apply(lambda x : get_adjectives(x))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.to_csv('df_adjectives.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To avoid data leakage, we need to perform next feature engineering after train/test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.content_clean, df.sentiment, test_size=0.20, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer_1000 = TfidfVectorizer(\n",
    "    max_df=0.1,\n",
    "    max_features = 1000,\n",
    "    strip_accents = 'ascii',\n",
    "    analyzer = 'word')\n",
    "\n",
    "vectorizer_2500 = TfidfVectorizer(\n",
    "    max_df=0.1,\n",
    "    max_features = 2500,\n",
    "    strip_accents = 'ascii',\n",
    "    analyzer = 'word')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1000 = vectorizer_1000.fit_transform(X_train).todense()\n",
    "X_test_1000 = vectorizer_1000.transform(X_test).todense()\n",
    "\n",
    "X_train_2500 = vectorizer_2500.fit_transform(X_train).todense()\n",
    "X_test_2500 = vectorizer_2500.transform(X_test).todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the number of features given by tf idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31969, 1000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_1000.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31969, 2500)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_2500.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the TF IDF representation is very sparse, we can use a dimension reduction method.\n",
    "It is actually too long to run.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=1000)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_train_pca.to_csv('X_train_pca.csv')\n",
    "X_test_pca.to_csv('X_test_pca.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use a XGBoost model, that can well handel sparse data, and which provides a convenient sample_weight parameter that will help us deal with class imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'anger': 0.9090909090909091,\n",
       " 'boredom': 0.5586592178770949,\n",
       " 'enthusiasm': 0.13175230566534915,\n",
       " 'empty': 0.12121212121212122,\n",
       " 'hate': 0.07564296520423601,\n",
       " 'relief': 0.0655307994757536,\n",
       " 'fun': 0.05630630630630631,\n",
       " 'surprise': 0.045829514207149404,\n",
       " 'love': 0.026028110359187923,\n",
       " 'sadness': 0.019372336303758234,\n",
       " 'happiness': 0.019201228878648235,\n",
       " 'worry': 0.011830119484206791,\n",
       " 'neutral': 0.011603620329542817}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping = df.groupby('sentiment').count().sort_values(by = 'tweet_id')['tweet_id']\n",
    "mapping = mapping.apply(lambda x : 100/x)\n",
    "mapping = mapping.to_dict()\n",
    "mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36861    0.019372\n",
       "27157    0.065531\n",
       "38264    0.019201\n",
       "8537     0.011604\n",
       "37527    0.011604\n",
       "           ...   \n",
       "7825     0.075643\n",
       "32542    0.011604\n",
       "5203     0.011604\n",
       "12187    0.011830\n",
       "33034    0.011604\n",
       "Name: sentiment, Length: 31969, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = pd.DataFrame(y_train).replace(mapping)\n",
    "sample_weight['sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=3)]: Done  27 out of  27 | elapsed: 53.3min finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.747099\tvalidation_1-merror:0.740148\n",
      "[1]\tvalidation_0-merror:0.747818\tvalidation_1-merror:0.741649\n",
      "[2]\tvalidation_0-merror:0.746442\tvalidation_1-merror:0.740273\n",
      "[3]\tvalidation_0-merror:0.747224\tvalidation_1-merror:0.741023\n",
      "[4]\tvalidation_0-merror:0.747818\tvalidation_1-merror:0.740648\n",
      "[5]\tvalidation_0-merror:0.747067\tvalidation_1-merror:0.740273\n",
      "[6]\tvalidation_0-merror:0.75054\tvalidation_1-merror:0.743526\n",
      "[7]\tvalidation_0-merror:0.756983\tvalidation_1-merror:0.747654\n",
      "[8]\tvalidation_0-merror:0.756764\tvalidation_1-merror:0.747779\n",
      "[9]\tvalidation_0-merror:0.757077\tvalidation_1-merror:0.74828\n",
      "[10]\tvalidation_0-merror:0.759548\tvalidation_1-merror:0.750156\n",
      "[11]\tvalidation_0-merror:0.759548\tvalidation_1-merror:0.749906\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112.482367</td>\n",
       "      <td>0.161901</td>\n",
       "      <td>4.425345</td>\n",
       "      <td>0.042389</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 3, 'objective...</td>\n",
       "      <td>0.199447</td>\n",
       "      <td>0.146221</td>\n",
       "      <td>0.202113</td>\n",
       "      <td>0.182596</td>\n",
       "      <td>0.025741</td>\n",
       "      <td>6</td>\n",
       "      <td>0.202445</td>\n",
       "      <td>0.146149</td>\n",
       "      <td>0.211283</td>\n",
       "      <td>0.186626</td>\n",
       "      <td>0.028848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>242.037870</td>\n",
       "      <td>1.000123</td>\n",
       "      <td>4.265003</td>\n",
       "      <td>0.125345</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 7, 'objective...</td>\n",
       "      <td>0.204417</td>\n",
       "      <td>0.150413</td>\n",
       "      <td>0.199669</td>\n",
       "      <td>0.184836</td>\n",
       "      <td>0.024415</td>\n",
       "      <td>5</td>\n",
       "      <td>0.206863</td>\n",
       "      <td>0.150114</td>\n",
       "      <td>0.209676</td>\n",
       "      <td>0.188884</td>\n",
       "      <td>0.027439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>379.176980</td>\n",
       "      <td>0.647166</td>\n",
       "      <td>4.244648</td>\n",
       "      <td>0.286854</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 12, 'objectiv...</td>\n",
       "      <td>0.210573</td>\n",
       "      <td>0.159215</td>\n",
       "      <td>0.212466</td>\n",
       "      <td>0.194087</td>\n",
       "      <td>0.024668</td>\n",
       "      <td>1</td>\n",
       "      <td>0.214228</td>\n",
       "      <td>0.160410</td>\n",
       "      <td>0.223871</td>\n",
       "      <td>0.199503</td>\n",
       "      <td>0.027922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140.583703</td>\n",
       "      <td>0.546380</td>\n",
       "      <td>4.139387</td>\n",
       "      <td>0.127006</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 3, 'objective...</td>\n",
       "      <td>0.201925</td>\n",
       "      <td>0.146981</td>\n",
       "      <td>0.129174</td>\n",
       "      <td>0.159368</td>\n",
       "      <td>0.030966</td>\n",
       "      <td>9</td>\n",
       "      <td>0.210014</td>\n",
       "      <td>0.153830</td>\n",
       "      <td>0.138204</td>\n",
       "      <td>0.167349</td>\n",
       "      <td>0.030836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316.213172</td>\n",
       "      <td>3.757035</td>\n",
       "      <td>4.143065</td>\n",
       "      <td>0.188420</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 7, 'objective...</td>\n",
       "      <td>0.203158</td>\n",
       "      <td>0.155619</td>\n",
       "      <td>0.200842</td>\n",
       "      <td>0.186542</td>\n",
       "      <td>0.021884</td>\n",
       "      <td>4</td>\n",
       "      <td>0.211292</td>\n",
       "      <td>0.161717</td>\n",
       "      <td>0.212574</td>\n",
       "      <td>0.195194</td>\n",
       "      <td>0.023678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>532.488395</td>\n",
       "      <td>1.546594</td>\n",
       "      <td>4.272064</td>\n",
       "      <td>0.103683</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 12, 'objectiv...</td>\n",
       "      <td>0.202467</td>\n",
       "      <td>0.161870</td>\n",
       "      <td>0.210296</td>\n",
       "      <td>0.191545</td>\n",
       "      <td>0.021224</td>\n",
       "      <td>2</td>\n",
       "      <td>0.213559</td>\n",
       "      <td>0.165922</td>\n",
       "      <td>0.224709</td>\n",
       "      <td>0.201397</td>\n",
       "      <td>0.025494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>187.580900</td>\n",
       "      <td>1.135378</td>\n",
       "      <td>4.107017</td>\n",
       "      <td>0.086813</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 3, 'objectiv...</td>\n",
       "      <td>0.191040</td>\n",
       "      <td>0.142282</td>\n",
       "      <td>0.198026</td>\n",
       "      <td>0.177117</td>\n",
       "      <td>0.024795</td>\n",
       "      <td>8</td>\n",
       "      <td>0.201802</td>\n",
       "      <td>0.153298</td>\n",
       "      <td>0.207456</td>\n",
       "      <td>0.187519</td>\n",
       "      <td>0.024308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>424.159693</td>\n",
       "      <td>2.318401</td>\n",
       "      <td>4.099035</td>\n",
       "      <td>0.202259</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 7, 'objectiv...</td>\n",
       "      <td>0.201374</td>\n",
       "      <td>0.145283</td>\n",
       "      <td>0.200747</td>\n",
       "      <td>0.182471</td>\n",
       "      <td>0.026294</td>\n",
       "      <td>7</td>\n",
       "      <td>0.213232</td>\n",
       "      <td>0.157655</td>\n",
       "      <td>0.212942</td>\n",
       "      <td>0.194610</td>\n",
       "      <td>0.026131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>721.038869</td>\n",
       "      <td>1.711363</td>\n",
       "      <td>3.310483</td>\n",
       "      <td>0.616027</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 12, 'objecti...</td>\n",
       "      <td>0.202931</td>\n",
       "      <td>0.157849</td>\n",
       "      <td>0.210094</td>\n",
       "      <td>0.190293</td>\n",
       "      <td>0.023124</td>\n",
       "      <td>3</td>\n",
       "      <td>0.218440</td>\n",
       "      <td>0.168050</td>\n",
       "      <td>0.225316</td>\n",
       "      <td>0.203935</td>\n",
       "      <td>0.025530</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     112.482367      0.161901         4.425345        0.042389   \n",
       "1     242.037870      1.000123         4.265003        0.125345   \n",
       "2     379.176980      0.647166         4.244648        0.286854   \n",
       "3     140.583703      0.546380         4.139387        0.127006   \n",
       "4     316.213172      3.757035         4.143065        0.188420   \n",
       "5     532.488395      1.546594         4.272064        0.103683   \n",
       "6     187.580900      1.135378         4.107017        0.086813   \n",
       "7     424.159693      2.318401         4.099035        0.202259   \n",
       "8     721.038869      1.711363         3.310483        0.616027   \n",
       "\n",
       "  param_max_depth param_n_estimators param_objective  \\\n",
       "0               3                  3   multi:softmax   \n",
       "1               3                  7   multi:softmax   \n",
       "2               3                 12   multi:softmax   \n",
       "3               7                  3   multi:softmax   \n",
       "4               7                  7   multi:softmax   \n",
       "5               7                 12   multi:softmax   \n",
       "6              12                  3   multi:softmax   \n",
       "7              12                  7   multi:softmax   \n",
       "8              12                 12   multi:softmax   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'max_depth': 3, 'n_estimators': 3, 'objective...           0.199447   \n",
       "1  {'max_depth': 3, 'n_estimators': 7, 'objective...           0.204417   \n",
       "2  {'max_depth': 3, 'n_estimators': 12, 'objectiv...           0.210573   \n",
       "3  {'max_depth': 7, 'n_estimators': 3, 'objective...           0.201925   \n",
       "4  {'max_depth': 7, 'n_estimators': 7, 'objective...           0.203158   \n",
       "5  {'max_depth': 7, 'n_estimators': 12, 'objectiv...           0.202467   \n",
       "6  {'max_depth': 12, 'n_estimators': 3, 'objectiv...           0.191040   \n",
       "7  {'max_depth': 12, 'n_estimators': 7, 'objectiv...           0.201374   \n",
       "8  {'max_depth': 12, 'n_estimators': 12, 'objecti...           0.202931   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.146221           0.202113         0.182596        0.025741   \n",
       "1           0.150413           0.199669         0.184836        0.024415   \n",
       "2           0.159215           0.212466         0.194087        0.024668   \n",
       "3           0.146981           0.129174         0.159368        0.030966   \n",
       "4           0.155619           0.200842         0.186542        0.021884   \n",
       "5           0.161870           0.210296         0.191545        0.021224   \n",
       "6           0.142282           0.198026         0.177117        0.024795   \n",
       "7           0.145283           0.200747         0.182471        0.026294   \n",
       "8           0.157849           0.210094         0.190293        0.023124   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                6            0.202445            0.146149   \n",
       "1                5            0.206863            0.150114   \n",
       "2                1            0.214228            0.160410   \n",
       "3                9            0.210014            0.153830   \n",
       "4                4            0.211292            0.161717   \n",
       "5                2            0.213559            0.165922   \n",
       "6                8            0.201802            0.153298   \n",
       "7                7            0.213232            0.157655   \n",
       "8                3            0.218440            0.168050   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.211283          0.186626         0.028848  \n",
       "1            0.209676          0.188884         0.027439  \n",
       "2            0.223871          0.199503         0.027922  \n",
       "3            0.138204          0.167349         0.030836  \n",
       "4            0.212574          0.195194         0.023678  \n",
       "5            0.224709          0.201397         0.025494  \n",
       "6            0.207456          0.187519         0.024308  \n",
       "7            0.212942          0.194610         0.026131  \n",
       "8            0.225316          0.203935         0.025530  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "parameters = {'objective':['multi:softmax'],\n",
    "              'n_estimators':[3, 7, 12],\n",
    "              'max_depth': [3, 5]}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    xgb_clf,\n",
    "    parameters,\n",
    "    scoring = 'f1_weighted',\n",
    "    cv = 3,\n",
    "    return_train_score = True,\n",
    "    verbose = 3, \n",
    "    n_jobs=3)\n",
    "\n",
    "\n",
    "search = clf.fit(X_train_1000, y_train, eval_set=[(X_train_1000, y_train), (X_test_1000, y_test)], sample_weight = sample_weight['sentiment'])\n",
    "evals_result = search.cv_results_\n",
    "pd.DataFrame(evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=3)]: Using backend LokyBackend with 3 concurrent workers.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=3)]: Done  27 out of  27 | elapsed: 137.6min finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.747255\tvalidation_1-merror:0.739897\n",
      "[1]\tvalidation_0-merror:0.746755\tvalidation_1-merror:0.739522\n",
      "[2]\tvalidation_0-merror:0.749195\tvalidation_1-merror:0.741524\n",
      "[3]\tvalidation_0-merror:0.750477\tvalidation_1-merror:0.742274\n",
      "[4]\tvalidation_0-merror:0.750196\tvalidation_1-merror:0.741774\n",
      "[5]\tvalidation_0-merror:0.750258\tvalidation_1-merror:0.740773\n",
      "[6]\tvalidation_0-merror:0.749601\tvalidation_1-merror:0.740148\n",
      "[7]\tvalidation_0-merror:0.751697\tvalidation_1-merror:0.7424\n",
      "[8]\tvalidation_0-merror:0.751165\tvalidation_1-merror:0.7424\n",
      "[9]\tvalidation_0-merror:0.754137\tvalidation_1-merror:0.743901\n",
      "[10]\tvalidation_0-merror:0.750321\tvalidation_1-merror:0.741524\n",
      "[11]\tvalidation_0-merror:0.750633\tvalidation_1-merror:0.741899\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>300.189172</td>\n",
       "      <td>3.545308</td>\n",
       "      <td>11.687829</td>\n",
       "      <td>0.213794</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 3, 'objective...</td>\n",
       "      <td>0.210664</td>\n",
       "      <td>0.210529</td>\n",
       "      <td>0.200193</td>\n",
       "      <td>0.207130</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>5</td>\n",
       "      <td>0.208727</td>\n",
       "      <td>0.213127</td>\n",
       "      <td>0.211424</td>\n",
       "      <td>0.211093</td>\n",
       "      <td>0.001811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>568.273706</td>\n",
       "      <td>2.971035</td>\n",
       "      <td>11.440419</td>\n",
       "      <td>0.170469</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 7, 'objective...</td>\n",
       "      <td>0.213724</td>\n",
       "      <td>0.213771</td>\n",
       "      <td>0.203416</td>\n",
       "      <td>0.210304</td>\n",
       "      <td>0.004870</td>\n",
       "      <td>4</td>\n",
       "      <td>0.213617</td>\n",
       "      <td>0.214397</td>\n",
       "      <td>0.215375</td>\n",
       "      <td>0.214463</td>\n",
       "      <td>0.000719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>950.223689</td>\n",
       "      <td>1.634732</td>\n",
       "      <td>10.733769</td>\n",
       "      <td>0.186247</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 3, 'n_estimators': 12, 'objectiv...</td>\n",
       "      <td>0.218182</td>\n",
       "      <td>0.213668</td>\n",
       "      <td>0.211333</td>\n",
       "      <td>0.214395</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>1</td>\n",
       "      <td>0.219146</td>\n",
       "      <td>0.214267</td>\n",
       "      <td>0.226331</td>\n",
       "      <td>0.219914</td>\n",
       "      <td>0.004955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>357.884498</td>\n",
       "      <td>2.505202</td>\n",
       "      <td>10.785941</td>\n",
       "      <td>0.132882</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 3, 'objective...</td>\n",
       "      <td>0.219453</td>\n",
       "      <td>0.214686</td>\n",
       "      <td>0.199814</td>\n",
       "      <td>0.211320</td>\n",
       "      <td>0.008364</td>\n",
       "      <td>3</td>\n",
       "      <td>0.221999</td>\n",
       "      <td>0.222965</td>\n",
       "      <td>0.213564</td>\n",
       "      <td>0.219509</td>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>798.507400</td>\n",
       "      <td>3.191034</td>\n",
       "      <td>10.718282</td>\n",
       "      <td>0.834017</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 7, 'objective...</td>\n",
       "      <td>0.216510</td>\n",
       "      <td>0.215296</td>\n",
       "      <td>0.202533</td>\n",
       "      <td>0.211447</td>\n",
       "      <td>0.006322</td>\n",
       "      <td>2</td>\n",
       "      <td>0.221280</td>\n",
       "      <td>0.223682</td>\n",
       "      <td>0.219285</td>\n",
       "      <td>0.221416</td>\n",
       "      <td>0.001798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1314.524730</td>\n",
       "      <td>4.255630</td>\n",
       "      <td>10.784820</td>\n",
       "      <td>0.155356</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 7, 'n_estimators': 12, 'objectiv...</td>\n",
       "      <td>0.221255</td>\n",
       "      <td>0.160292</td>\n",
       "      <td>0.212826</td>\n",
       "      <td>0.198128</td>\n",
       "      <td>0.026972</td>\n",
       "      <td>6</td>\n",
       "      <td>0.227809</td>\n",
       "      <td>0.167961</td>\n",
       "      <td>0.231393</td>\n",
       "      <td>0.209054</td>\n",
       "      <td>0.029094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>469.983015</td>\n",
       "      <td>1.217408</td>\n",
       "      <td>10.765334</td>\n",
       "      <td>0.348389</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 3, 'objectiv...</td>\n",
       "      <td>0.216899</td>\n",
       "      <td>0.142451</td>\n",
       "      <td>0.196225</td>\n",
       "      <td>0.185196</td>\n",
       "      <td>0.031379</td>\n",
       "      <td>9</td>\n",
       "      <td>0.218686</td>\n",
       "      <td>0.155736</td>\n",
       "      <td>0.209616</td>\n",
       "      <td>0.194679</td>\n",
       "      <td>0.027785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1144.055695</td>\n",
       "      <td>6.086999</td>\n",
       "      <td>14.245700</td>\n",
       "      <td>0.834904</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 7, 'objectiv...</td>\n",
       "      <td>0.212936</td>\n",
       "      <td>0.147702</td>\n",
       "      <td>0.202288</td>\n",
       "      <td>0.187646</td>\n",
       "      <td>0.028575</td>\n",
       "      <td>8</td>\n",
       "      <td>0.217688</td>\n",
       "      <td>0.159704</td>\n",
       "      <td>0.217448</td>\n",
       "      <td>0.198280</td>\n",
       "      <td>0.027277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1955.724897</td>\n",
       "      <td>10.534521</td>\n",
       "      <td>10.747977</td>\n",
       "      <td>0.275600</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 12, 'n_estimators': 12, 'objecti...</td>\n",
       "      <td>0.214370</td>\n",
       "      <td>0.154546</td>\n",
       "      <td>0.217299</td>\n",
       "      <td>0.195407</td>\n",
       "      <td>0.028915</td>\n",
       "      <td>7</td>\n",
       "      <td>0.224553</td>\n",
       "      <td>0.166892</td>\n",
       "      <td>0.234358</td>\n",
       "      <td>0.208601</td>\n",
       "      <td>0.029763</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0     300.189172      3.545308        11.687829        0.213794   \n",
       "1     568.273706      2.971035        11.440419        0.170469   \n",
       "2     950.223689      1.634732        10.733769        0.186247   \n",
       "3     357.884498      2.505202        10.785941        0.132882   \n",
       "4     798.507400      3.191034        10.718282        0.834017   \n",
       "5    1314.524730      4.255630        10.784820        0.155356   \n",
       "6     469.983015      1.217408        10.765334        0.348389   \n",
       "7    1144.055695      6.086999        14.245700        0.834904   \n",
       "8    1955.724897     10.534521        10.747977        0.275600   \n",
       "\n",
       "  param_max_depth param_n_estimators param_objective  \\\n",
       "0               3                  3   multi:softmax   \n",
       "1               3                  7   multi:softmax   \n",
       "2               3                 12   multi:softmax   \n",
       "3               7                  3   multi:softmax   \n",
       "4               7                  7   multi:softmax   \n",
       "5               7                 12   multi:softmax   \n",
       "6              12                  3   multi:softmax   \n",
       "7              12                  7   multi:softmax   \n",
       "8              12                 12   multi:softmax   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'max_depth': 3, 'n_estimators': 3, 'objective...           0.210664   \n",
       "1  {'max_depth': 3, 'n_estimators': 7, 'objective...           0.213724   \n",
       "2  {'max_depth': 3, 'n_estimators': 12, 'objectiv...           0.218182   \n",
       "3  {'max_depth': 7, 'n_estimators': 3, 'objective...           0.219453   \n",
       "4  {'max_depth': 7, 'n_estimators': 7, 'objective...           0.216510   \n",
       "5  {'max_depth': 7, 'n_estimators': 12, 'objectiv...           0.221255   \n",
       "6  {'max_depth': 12, 'n_estimators': 3, 'objectiv...           0.216899   \n",
       "7  {'max_depth': 12, 'n_estimators': 7, 'objectiv...           0.212936   \n",
       "8  {'max_depth': 12, 'n_estimators': 12, 'objecti...           0.214370   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.210529           0.200193         0.207130        0.004904   \n",
       "1           0.213771           0.203416         0.210304        0.004870   \n",
       "2           0.213668           0.211333         0.214395        0.002843   \n",
       "3           0.214686           0.199814         0.211320        0.008364   \n",
       "4           0.215296           0.202533         0.211447        0.006322   \n",
       "5           0.160292           0.212826         0.198128        0.026972   \n",
       "6           0.142451           0.196225         0.185196        0.031379   \n",
       "7           0.147702           0.202288         0.187646        0.028575   \n",
       "8           0.154546           0.217299         0.195407        0.028915   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                5            0.208727            0.213127   \n",
       "1                4            0.213617            0.214397   \n",
       "2                1            0.219146            0.214267   \n",
       "3                3            0.221999            0.222965   \n",
       "4                2            0.221280            0.223682   \n",
       "5                6            0.227809            0.167961   \n",
       "6                9            0.218686            0.155736   \n",
       "7                8            0.217688            0.159704   \n",
       "8                7            0.224553            0.166892   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.211424          0.211093         0.001811  \n",
       "1            0.215375          0.214463         0.000719  \n",
       "2            0.226331          0.219914         0.004955  \n",
       "3            0.213564          0.219509         0.004223  \n",
       "4            0.219285          0.221416         0.001798  \n",
       "5            0.231393          0.209054         0.029094  \n",
       "6            0.209616          0.194679         0.027785  \n",
       "7            0.217448          0.198280         0.027277  \n",
       "8            0.234358          0.208601         0.029763  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'objective':['multi:softmax'],\n",
    "              'n_estimators':[3, 7, 12],\n",
    "              'max_depth': [3, 7, 12]}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    xgb_clf,\n",
    "    parameters,\n",
    "    scoring = 'f1_weighted',\n",
    "    cv = 3,\n",
    "    return_train_score = True,\n",
    "    verbose = 3, \n",
    "    n_jobs=3)\n",
    "\n",
    "\n",
    "search = clf.fit(X_train_2500, y_train, eval_set=[(X_train_2500, y_train), (X_test_2500, y_test)], sample_weight = sample_weight['sentiment'])\n",
    "evals_result = search.cv_results_\n",
    "pd.DataFrame(evals_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed: 94.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=4)]: Done   3 out of   3 | elapsed: 94.2min finished\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n",
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:588: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  data.base is not None and isinstance(data, np.ndarray) \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-merror:0.75251\tvalidation_1-merror:0.742775\n",
      "[1]\tvalidation_0-merror:0.752166\tvalidation_1-merror:0.744026\n",
      "[2]\tvalidation_0-merror:0.755357\tvalidation_1-merror:0.745652\n",
      "[3]\tvalidation_0-merror:0.753887\tvalidation_1-merror:0.746778\n",
      "[4]\tvalidation_0-merror:0.751853\tvalidation_1-merror:0.746528\n",
      "[5]\tvalidation_0-merror:0.753761\tvalidation_1-merror:0.747279\n",
      "[6]\tvalidation_0-merror:0.753949\tvalidation_1-merror:0.748655\n",
      "[7]\tvalidation_0-merror:0.757046\tvalidation_1-merror:0.752533\n",
      "[8]\tvalidation_0-merror:0.757234\tvalidation_1-merror:0.752784\n",
      "[9]\tvalidation_0-merror:0.75398\tvalidation_1-merror:0.749656\n",
      "[10]\tvalidation_0-merror:0.75348\tvalidation_1-merror:0.750907\n",
      "[11]\tvalidation_0-merror:0.752698\tvalidation_1-merror:0.748655\n",
      "[12]\tvalidation_0-merror:0.755388\tvalidation_1-merror:0.752158\n",
      "[13]\tvalidation_0-merror:0.755482\tvalidation_1-merror:0.752158\n",
      "[14]\tvalidation_0-merror:0.756264\tvalidation_1-merror:0.753659\n",
      "[15]\tvalidation_0-merror:0.756107\tvalidation_1-merror:0.753409\n",
      "[16]\tvalidation_0-merror:0.75714\tvalidation_1-merror:0.75466\n",
      "[17]\tvalidation_0-merror:0.757046\tvalidation_1-merror:0.754535\n",
      "[18]\tvalidation_0-merror:0.756514\tvalidation_1-merror:0.754285\n",
      "[19]\tvalidation_0-merror:0.756326\tvalidation_1-merror:0.754285\n",
      "[20]\tvalidation_0-merror:0.757515\tvalidation_1-merror:0.756287\n",
      "[21]\tvalidation_0-merror:0.756858\tvalidation_1-merror:0.758539\n",
      "[22]\tvalidation_0-merror:0.756201\tvalidation_1-merror:0.757538\n",
      "[23]\tvalidation_0-merror:0.754825\tvalidation_1-merror:0.756912\n",
      "[24]\tvalidation_0-merror:0.755357\tvalidation_1-merror:0.758289\n",
      "[25]\tvalidation_0-merror:0.755357\tvalidation_1-merror:0.759289\n",
      "[26]\tvalidation_0-merror:0.757296\tvalidation_1-merror:0.762042\n",
      "[27]\tvalidation_0-merror:0.757077\tvalidation_1-merror:0.762167\n",
      "[28]\tvalidation_0-merror:0.757265\tvalidation_1-merror:0.762542\n",
      "[29]\tvalidation_0-merror:0.757515\tvalidation_1-merror:0.763418\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>param_objective</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5560.207621</td>\n",
       "      <td>30.461314</td>\n",
       "      <td>15.58864</td>\n",
       "      <td>3.206189</td>\n",
       "      <td>5</td>\n",
       "      <td>30</td>\n",
       "      <td>multi:softmax</td>\n",
       "      <td>{'max_depth': 5, 'n_estimators': 30, 'objectiv...</td>\n",
       "      <td>0.220374</td>\n",
       "      <td>0.159686</td>\n",
       "      <td>0.213599</td>\n",
       "      <td>0.197889</td>\n",
       "      <td>0.027152</td>\n",
       "      <td>1</td>\n",
       "      <td>0.230692</td>\n",
       "      <td>0.172469</td>\n",
       "      <td>0.232211</td>\n",
       "      <td>0.211791</td>\n",
       "      <td>0.027812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0    5560.207621     30.461314         15.58864        3.206189   \n",
       "\n",
       "  param_max_depth param_n_estimators param_objective  \\\n",
       "0               5                 30   multi:softmax   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0  {'max_depth': 5, 'n_estimators': 30, 'objectiv...           0.220374   \n",
       "\n",
       "   split1_test_score  split2_test_score  mean_test_score  std_test_score  \\\n",
       "0           0.159686           0.213599         0.197889        0.027152   \n",
       "\n",
       "   rank_test_score  split0_train_score  split1_train_score  \\\n",
       "0                1            0.230692            0.172469   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "0            0.232211          0.211791         0.027812  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer_5000 = TfidfVectorizer(\n",
    "    max_df=0.1,\n",
    "    max_features = 5000,\n",
    "    strip_accents = 'ascii',\n",
    "    analyzer = 'word')\n",
    "\n",
    "X_train_5000 = vectorizer_5000.fit_transform(X_train).todense()\n",
    "X_test_5000 = vectorizer_5000.transform(X_test).todense()\n",
    "\n",
    "parameters = {'objective':['multi:softmax'],\n",
    "              'n_estimators':[30],\n",
    "              'max_depth': [5]}\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier()\n",
    "\n",
    "clf = GridSearchCV(\n",
    "    xgb_clf,\n",
    "    parameters,\n",
    "    scoring = 'f1_weighted',\n",
    "    cv = 3,\n",
    "    return_train_score = True,\n",
    "    verbose = 4, \n",
    "    n_jobs=4)\n",
    "\n",
    "\n",
    "search = clf.fit(X_train_5000, y_train, eval_set=[(X_train_5000, y_train), (X_test_5000, y_test)], sample_weight = sample_weight['sentiment'])\n",
    "evals_result = search.cv_results_\n",
    "pd.DataFrame(evals_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next Steps:\n",
    "\n",
    "\n",
    "- Debug XGBoost\n",
    "- Take time to run and fine tune algorithme\n",
    "- Try different Algorithmes for classification\n",
    "- Compare performance when using PCA, Adjectives, more features after TF-IDF.\n",
    "- Improve Cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
